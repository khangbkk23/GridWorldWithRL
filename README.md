# ðŸ§  DQN GridWorld RL Project

A simple implementation of Deep Q-Learning (DQN) in a 4x4 GridWorld environment using PyTorch. The project allows you to train an agent, test its performance, and visualize results.

---

## ðŸ“ Folder Structure

```
.
â”œâ”€â”€ config/                    # YAML config files for environment setup
â”‚   â””â”€â”€ env.yaml
â”œâ”€â”€ models/                   # Saved trained models
â”‚   â”œâ”€â”€ dqn_gridworld_basic.pth
â”‚   â””â”€â”€ dqn_gridworld_maze.pth
â”œâ”€â”€ reinforcement/            # Core reinforcement learning modules
â”‚   â”œâ”€â”€ agent.py
â”‚   â”œâ”€â”€ dqn.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ results/                  # Output folder for plots, training results, etc.
â”œâ”€â”€ test/                     # Test script for basic functionality
â”‚   â””â”€â”€ test.py
â”œâ”€â”€ gridworld.py              # Environment definition (4x4 GridWorld)
â”œâ”€â”€ main.py                   # Entry point for training and testing
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                 # Project documentation
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Installation

```bash
# Create a virtual environment (optional but recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install required packages
pip install -r requirements.txt
```

---

## ðŸš€ Training the Agent

To train the agent in a specific environment (e.g., basic or maze):

```bash
python main.py --config gridworld_basic --episodes 1000
```

or for the maze version:

```bash
python main.py --config gridworld_maze --episodes 1500 --visualize
```

- `--episodes`: Number of episodes to train
- `--visualize`: (Optional) Turn on real-time training visualization

---

## ðŸ§ª Testing the Agent

Run all the built-in tests to verify the setup:

```bash
python test/test.py
```

This checks:
- GridWorld environment functionality
- DQN network architecture
- Agent logic
- Training loop

---

## ðŸ“Š Visualizing Results

After training with `--visualize`, the `results/` folder will contain:
- Training scores (plot image)
- Reward history
- Saved model weights in `models/`

You can also modify the plotting functions inside `utils.py` to customize the visuals.

---

## ðŸ›  Configuration

Edit `config/env.yaml` to modify:
- Grid size
- Reward structure
- Training hyperparameters

---

## âœ… Requirements

Make sure you're using:
- Python 3.12.3
- PyTorch >= 2.7.1 (CPU-only is fine)

---

## ðŸ“Œ Notes

- The project uses **one-hot encoding** for GridWorld states.
- Both Îµ-greedy strategy and target network synchronization are implemented.
- Modular design allows easy extension to other environments.